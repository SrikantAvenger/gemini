dist: trusty
language: scala
scala:
   - 2.11.2

sudo: required
services:
  - docker

env:
  global:
    - SPARK_HOME=./spark

matrix:
  fast_finish: true
  include:
  - scala: 2.11.2
    before_install:
    - ./scripts/start_docker_db.sh
    script:
      - tar -xzf src/test/resources/weighted-minhash/csv.tar.gz -C src/test/resources/weighted-minhash/
      - ./sbt "test-only * -- -l tags.FEIntegration"

  - scala: 2.11.2
    env: INTEGRATION_TESTS=true
    before_install:
      - ./scripts/start_docker_db.sh
      - ./scripts/start_docker_bblfsh.sh
      - ./scripts/install_python.sh
      - ./scripts/get_apache_spark.sh "2.2.0" "2.7" || travis_terminate 1
    install:
      - make build
    script:
      # start dependencies
      - VIRTUAL_ENV=None IN_BACKGROUND=1 ./feature_extractor
      # just check that commands don't fail
      - ./hash src/test/resources/siva || travis_terminate 1
      - ./query ./src/test/resources/LICENSE
      - ./report
      - go get ./src/main/go/... || true
      - go run ./src/main/go/query.go ./src/test/resources/LICENSE
    before_deploy:
      - VERSION=$TRAVIS_TAG ./scripts/release.sh
    deploy:
      - provider: releases
        api_key:
          secure: $GITHUB_TOKEN
        file_glob: true
        file: gemini_$TRAVIS_TAG.tar.gz
        skip_cleanup: true
        on:
          tags: true
      - provider: script
        script: make docker-push-latest
        on:
          tags: true
      - provider: script
        script: make docker-push
        on:
          branch: experimental

  - scala: 2.11.2
    env:
      - INTEGRATION_TESTS=true
      - MASTER=spark://127.0.0.1:7077
    before_install:
      - ./scripts/install_python.sh
      - ./scripts/start_docker_db.sh
      - ./scripts/start_docker_bblfsh.sh
      - ./scripts/get_apache_spark.sh "2.2.0" "2.7" || travis_terminate 1
    install:
      - make build
    script:
      # start dependencies
      - ./scripts/start_apache_spark_cluster.sh "127.0.0.1" "7077" || travis_terminate 1
      - VIRTUAL_ENV=None IN_BACKGROUND=1 ./feature_extractor
      # hashing test repositories
      - ./hash src/test/resources/siva || travis_terminate 1
      # query without similarity
      - ./query ./src/test/resources/LICENSE
      # report without similarity
      - ./report
      # query with similarity
      - docker cp ./src/test/resources/hashtables_dump.cql db:/hashtables_dump.cql
      - docker exec -it db cqlsh -e "SOURCE '/hashtables_dump.cql'"
      - ./query --doc-freq-file=src/test/resources/docfreq.json --params-file=src/test/resources/params.json --hashtables-num=9 --band-size=13 ./src/test/resources/consumer.go | tee query_result.txt
      # check both identical & similar files appeared in output
      - grep "Duplicates of ./src/test/resources/consumer.go" query_result.txt > /dev/null
      - grep "Similar files of ./src/test/resources/consumer.go" query_result.txt > /dev/null
      # report with similarity
      - ./report | tee report_result.txt
      # check both identical & similar files appeared in output
      - grep "2 duplicates" report_result.txt > /dev/null
      - grep "2 similar files" report_result.txt > /dev/null
      # go query
      - go get ./src/main/go/... || true
      - go run ./src/main/go/query.go ./src/test/resources/LICENSE

  - scala: 2.11.2
    env: STYLE_CHECK=true
    script: ./sbt scalastyle

  - scala: 2.11.2
    env: FE_PYTHON_TEST=true
    script:
      - docker build -t srcd/gemini-fe -f FE.Dockerfile .
      - docker run --rm -e PYTHONHASHSEED=0 srcd/gemini-fe pytest -v
      - docker run -p 9001:9001 -e PYTHONHASHSEED=0 -d srcd/gemini-fe
      - ./sbt "test-only * -- -n tags.FEIntegration"

  - scala: 2.11.2
    env: PYTHON_LINT_TESTS=true
    before_install:
      - sudo apt-get -qq update
      - sudo apt-get -y install python3-pip
      - pip3 install --user yapf
    script:
      - make lint-python

  - scala: 2.11.2
    env: PYTHON_LIB_TESTS=true
    before_install:
      - ./scripts/install_python.sh
    script:
      - pytest -v src/main/python/community-detector

after_failure:
 - docker logs db

before_cache:
  # Cleanup the cached directories to avoid unnecessary cache updates
  - find $HOME/.ivy2/cache -name "ivydata-*.properties" -print -delete
  - find $HOME/.sbt        -name "*.lock"               -print -delete
  # make bblfsh images readable
  - sudo chmod -R 777 $HOME/bblfsh-drivers/images

cache:
  directories:
    - .spark-dist
    - $HOME/.sbt
    - $HOME/.ivy2/cache
    - $HOME/.coursier
    - $HOME/bblfsh-drivers/images
    - $HOME/.cache/pip/wheels
